# üñºÔ∏è Local Multimodal Image Generation with Ollama & Stable Diffusion

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.7+](https://img.shields.io/badge/Python-3.7%2B-blue?logo=python)](https://www.python.org/)
[![Status: Active](https://img.shields.io/badge/Status-Active-brightgreen)](https://github.com)
[![Jupyter Notebook](https://img.shields.io/badge/Powered%20by-Jupyter-orange?logo=jupyter)](https://jupyter.org/)
[![Made with Python](https://img.shields.io/badge/Made%20with-Python-informational?logo=python&logoColor=white)](https://www.python.org/)

A fully local and private pipeline for high-quality image synthesis. This project seamlessly integrates a local Large Language Model (LLM) running on **Ollama** for automated, intelligent prompt engineering with the **Stable Diffusion WebUI (AUTOMATIC1111)** API for image generation and dynamic model checkpoint switching.

## üé® Sample Output

Below are examples of images generated by this pipeline:

> **üì∏ Note**: Sample images will appear here once we generate your first output. Generated images are automatically saved as `sd_generated_output_*.png` in your working directory.

## ‚ú® Key Features

- **ü§ñ Automated Prompt Enhancement**: Uses a local Ollama LLM (`brxce/stable-diffusion-prompt-generator`) to transform simple text ideas into complex, high-quality prompts
- **üîê Fully Local & Private**: No cloud dependencies‚Äîboth LLM and image generation run on our machine
- **üîÑ Dynamic Model Switching**: Switch between multiple Stable Diffusion checkpoints (`.safetensors`/`.ckpt`) without restarting
- **‚ö° Robust Error Handling**: Built-in fallback mechanisms for graceful degradation if services fail
- **üìì Jupyter-Ready**: Clean, modular Python implementation ideal for Jupyter notebooks or scripts
- **üéØ Type-Hinted Code**: Full type annotations for better code clarity and IDE support

## üìã Table of Contents

- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Workflow Overview](#workflow-overview)
- [API Configuration](#api-configuration)
- [Usage Examples](#usage-examples)
- [Troubleshooting](#troubleshooting)
- [Performance Tips](#performance-tips)
- [Project Structure](#project-structure)
- [References](#references)

## üì¶ Prerequisites

### Required Software
- **Stable Diffusion WebUI**: [AUTOMATIC1111/stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- **Ollama**: Download from [ollama.com](https://ollama.com)
- **Python**: 3.7 or higher

### Hardware Requirements
- **GPU**: NVIDIA GPU with 6GB+ VRAM (recommended) or CPU (slower)
- **Storage**: ~20GB for SD models + ~5GB for Ollama models
- **RAM**: 8GB minimum, 16GB+ recommended

## üöÄ Installation

### 1. Clone the Repository
```bash
git clone <your-url>
cd Transformer-based_learnings
```

### 2. Install Python Dependencies
```bash
pip install requests pillow
```

> **Note**: `torch`, `torchvision`, and `xformers` are required by the Stable Diffusion WebUI but not needed for this API client.

### 3. Set Up Ollama
```bash
# Start the Ollama server
ollama serve

# In a new terminal, pull the prompt generator model
ollama pull brxce/stable-diffusion-prompt-generator
```

### 4. Set Up Stable Diffusion WebUI
```bash
cd path/to/stable-diffusion-webui
python launch.py --api --no-half
```

**Important Flags:**
- `--api`: Enables the REST API (required)
- `--no-half`: Prevents half-precision (float16) issues with certain GPUs

## üèÉ Quick Start

1. **Configure your models** (in the notebook):
   ```python
   1. **Configure your model path** (in the notebook):
   Set the exact path to your SD model folder. The script will automatically discover all `.safetensors` and `.ckpt` files.
   
   MODEL_FOLDER_PATH = r"C:\AI\stable-diffusion-webui-master\models\Stable-diffusion"
    Select the model index: After discovery, models are sorted alphabetically. Change the index to select a different model.


MODEL_SELECTION_INDEX = 1  # Select the second model in the discovered list (Index 1)
   ```

2. **Run the notebook**:
   - Open `ollama_Image_PromptGenerator.ipynb` in Jupyter
   - Execute cells in order
   - Generated images will be saved to the current directory

3. **Check the output**:
   - Look for `sd_generated_output_*.png` files
   - Images display inline in Jupyter

## üß† Workflow Overview

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  User Idea      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Ollama Prompt Generation    ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Enhanced with negative keywords
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. Prompt Parsing              ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Separates positive/negative
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. Model Checkpoint Switch     ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Via A1111 /sdapi/v1/options
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. Image Generation (txt2img)  ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ Via A1111 /sdapi/v1/txt2img
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Output: Base64 ‚Üí PNG File       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Step-by-Step Breakdown

| Step | Service | Purpose |
|------|---------|---------|
| **1. Configuration** | Local | Define API endpoints and available SD models |
| **2. Prompt Generation** | Ollama | Transform simple ideas into detailed, enhanced prompts |
| **3. Prompt Parsing** | Local | Separate positive and negative prompt components |
| **4. Model Switching** | SD WebUI | Activate the selected checkpoint via `/sdapi/v1/options` |
| **5. Image Generation** | SD WebUI | Generate image via `/sdapi/v1/txt2img` |
| **6. Output Processing** | Local | Decode Base64, save PNG, and display |

## ‚öôÔ∏è API Configuration

### Endpoints

```python
SD_API_URL = "http://127.0.0.1:7860"              # Stable Diffusion WebUI
OLLAMA_URL = "http://localhost:11434/api/generate"  # Ollama
```

### Model Checkpoint Naming

> **Important**: Stable Diffusion model files often appear with hash suffixes in logs and UI (e.g., `protogenX34Pruned.safetensors [ef8629e2c8]`). **Only use the filename without the hash** in the `AVAILABLE_MODELS` list.

**Examples:**
```python
# ‚úÖ CORRECT - Use only the filename
# üé® Model Auto-Discovery Setup
MODEL_FOLDER_PATH = r"C:\AI\stable-diffusion-webui-master\models\Stable-diffusion"
SUPPORTED_EXTENSIONS = ('.safetensors', '.ckpt')

# AVAILABLE_MODELS list is now dynamically created by a function (see script)
AVAILABLE_MODELS = auto_discover_models(MODEL_FOLDER_PATH) 

# üí° Set the Active Model
# The index will select a model from the sorted list 
MODEL_SELECTION_INDEX = 1 
MODEL_TO_USE = AVAILABLE_MODELS[MODEL_SELECTION_INDEX]

# ‚ùå INCORRECT - Don't include the hash
# "protogenX34Pruned.safetensors [ef8629e2c8]"  # Wrong!
```

To find the exact filenames on your system:
```bash
# List all installed models
ls path/to/stable-diffusion-webui/models/Stable-diffusion/
```

### Generation Parameters

Customize image generation by modifying the `sd_payload`:

```python
sd_payload = {
    "prompt": positive_prompt,           # Main prompt
    "negative_prompt": negative_prompt,  # What to avoid
    "steps": 25,                         # Quality vs speed (20-50 recommended)
    "cfg_scale": 7,                      # Prompt adherence (5-15 typical)
    "sampler_index": "Euler a",          # Algorithm choice
    "width": 768,                        # Output width (multiple of 64)
    "height": 512,                       # Output height (multiple of 64)
    "batch_size": 1                      # Images per run
}
```

#### Parameter Recommendations

| Parameter | Range | Notes |
|-----------|-------|-------|
| **steps** | 20-50 | Higher = better quality but slower (~0.5s per step on RTX 3090) |
| **cfg_scale** | 5-15 | 7-8 is balanced; higher enforces prompt more strictly |
| **width/height** | 512-768 | Must be multiples of 64; larger = more VRAM needed |
| **sampler_index** | Euler a, DPM++, DDIM | Experiment to find preferred quality/speed trade-off |

## üíª Core Code Components

### Configuration & Model Selection

```python
# --- Configuration ---
SD_API_URL = "http://127.0.0.1:7860"
OLLAMA_URL = "http://localhost:11434/api/generate"

# üé® Available Stable Diffusion Checkpoints
AVAILABLE_MODELS = [
    "protogenX34Pruned.8NEd.safetensors",
    "realisticVisionV60B1_v51HyperVAE.safetensors",
    "v1-5-pruned-emaonly.safetensors"
]

# üí° Set the Active Model
MODEL_SELECTION_INDEX = 1 
MODEL_TO_USE = AVAILABLE_MODELS[MODEL_SELECTION_INDEX]
```

### Model Switching Function

```python
def switch_sd_checkpoint(model_name: str, api_url: str = SD_API_URL) -> bool:
    """
    Switches the active Stable Diffusion model checkpoint via the A1111 API.
    
    Args:
        model_name: Exact filename of the model checkpoint
        api_url: Stable Diffusion WebUI API endpoint
    
    Returns:
        True if successful, False otherwise
    """
    options_endpoint = f"{api_url}/sdapi/v1/options"
    switch_payload = {"sd_model_checkpoint": model_name}
    
    print(f"Attempting to switch model to: {model_name}")
    
    try:
        response = requests.post(options_endpoint, json=switch_payload, timeout=30)
        
        if response.status_code == 200:
            print("‚úÖ Model switch successful.")
            return True
        else:
            print(f"‚ùå API Call Failed. Status Code: {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"‚ùå Connection Error: {e}")
        return False
```

### Prompt Parsing Function

```python
def parse_prompt_output(prompt_string: str) -> Tuple[str, str]:
    """
    Intelligently parses LLM output into positive and negative prompts.
    
    Supports multiple delimiter formats:
    - "NEGATIVE PROMPT:", "Negative Prompt:", "NEGATIVE:", "Negative:"
    
    Args:
        prompt_string: Raw output from Ollama LLM
    
    Returns:
        Tuple of (positive_prompt, negative_prompt)
        
    Note:
        If no delimiter found, returns full string as positive prompt
        with empty negative prompt.
    """
    delimiters = ["NEGATIVE PROMPT:", "Negative Prompt:", "NEGATIVE:", "Negative:"]
    
    for delimiter in delimiters:
        if delimiter in prompt_string:
            parts = prompt_string.split(delimiter, 1)
            positive = parts[0].strip().strip(',').strip()
            negative = parts[1].strip().strip(',').strip()
            return positive, negative
    
    print("‚ö†Ô∏è Warning: No negative prompt delimiter found. Using full string as positive.")
    return prompt_string, ""
```

## üìö Usage Examples

### Example 1: Basic Image Generation

```python
# Define your idea
base_prompt = "A serene mountain landscape at sunset with golden light"

# Enhance via Ollama, generate image with Model 0
MODEL_SELECTION_INDEX = 0
MODEL_TO_USE = AVAILABLE_MODELS[MODEL_SELECTION_INDEX]

# Run the full pipeline (see notebook cells)
```

### Example 2: Switch Between Models for Comparison

```python
# Generate with Model 1
MODEL_SELECTION_INDEX = 1
switch_sd_checkpoint(MODEL_TO_USE)
# ... run image generation ...

# Generate with Model 2
MODEL_SELECTION_INDEX = 2
switch_sd_checkpoint(MODEL_TO_USE)
# ... run image generation again ...
```

### Example 3: Custom Negative Prompt

```python
NEGATIVE_PROMPT_KEYWORDS = "blurry, watermark, text, low quality, distorted"
base_prompt = f"Your idea here... Avoid: {NEGATIVE_PROMPT_KEYWORDS}"
```

### Example 4: Finding and Adding New Models

If you see a model in your SD WebUI with a hash like `realisticVisionV60B1_v51HyperVAE [a0d5b3e123]`:

```python
# Extract the filename only (ignore the hash in brackets)
AVAILABLE_MODELS = [
    "protogenX34Pruned.safetensors",
    "realisticVisionV60B1_v51HyperVAE.safetensors",  # ‚úÖ Correct
    "v1-5-pruned-emaonly.safetensors",
    # "realisticVisionV60B1_v51HyperVAE [a0d5b3e123]"  # ‚ùå Wrong - don't include hash
]
```

## üîß Troubleshooting

| Issue | Cause | Solution |
|-------|-------|----------|
| `ConnectionError: Failed to establish connection` | SD WebUI not running | Start with `python launch.py --api --no-half` |
| `API returns 'Not Found' (404)` | Wrong endpoint URL or API not enabled | Verify `SD_API_URL` and use `--api` flag |
| `NansException` error during generation | Half-precision (float16) issue | Start WebUI with `--no-half` flag |
| `Ollama not reachable` | Ollama server not running or model not pulled | Run `ollama serve` and `ollama pull brxce/stable-diffusion-prompt-generator` |
| `Timeout error during generation` | Generation taking too long | Increase timeout in `requests.post()` call (e.g., to 300 seconds) |
| `CUDA out of memory` | Batch too large or resolution too high | Reduce `width`, `height`, or `batch_size` |
| `Model file not found` | Checkpoint name typo or wrong filename | Verify exact filename matches SD WebUI installation |

### Debug Tips

1. **Check service status**:
   ```bash
   # Test Ollama
   curl http://localhost:11434/api/tags
   
   # Test Stable Diffusion
   curl http://127.0.0.1:7860/api/sd-models
   ```

2. **Enable verbose logging**:
   ```python
   import logging
   logging.basicConfig(level=logging.DEBUG)
   ```

3. **Increase timeout for slow systems**:
   ```python
   requests.post(url, json=payload, timeout=300)  # 5 minutes
   ```

## ‚ö° Performance Tips

### For Faster Generation
- Use fewer steps (20 instead of 50) ‚Äì reduces quality slightly
- Reduce resolution (512√ó512 instead of 768√ó512)
- Use simpler samplers (Euler instead of DPM++)

### For Better Quality
- Increase steps (40-50)
- Use higher resolution (768√ó768 or higher)
- Use higher cfg_scale (8-10)
- Use advanced samplers (DPM++ 2M Karras)

### Memory Optimization
- Use `--lowvram` or `--medvram` flags in SD WebUI if running on limited VRAM
- Reduce `width` and `height` to 512
- Set `batch_size = 1`

### Timing Estimates (RTX 3090)
| Resolution | Steps | Time |
|------------|-------|------|
| 512√ó512 | 20 | ~10 seconds |
| 512√ó512 | 50 | ~25 seconds |
| 768√ó768 | 25 | ~30 seconds |
| 768√ó768 | 50 | ~60 seconds |

## üìÇ Project Structure

```
Transformer-based_learnings/
‚îú‚îÄ‚îÄ ollama_Image_PromptGenerator.ipynb    # Main notebook
‚îú‚îÄ‚îÄ README.md                             # This file
‚îî‚îÄ‚îÄ sd_generated_output_*.png             # Generated images (auto-created)
```

### Notebook Cells Breakdown

| Cell # | Type | Purpose |
|--------|------|---------|
| 1 | Code | Install dependencies (commented) |
| 2 | Markdown | Query model section header |
| 3 | Markdown | Image generation section header |
| 4 | Code | Version checks and imports |
| 5 | Markdown | Model selection header |
| 6 | Code | Configuration & utility functions |
| 7 | Markdown | Ollama prompt generation header |
| 8 | Code | Ollama prompt enhancement logic |
| 9 | Markdown | Model switching header |
| 10 | Code | Switch SD checkpoint |
| 11 | Markdown | Image generation header |
| 12 | Code | Generate and save image |
| 13 | Code | Cleanup (empty) |

## üîó References

- **Ollama**: https://ollama.com
- **Ollama Models**: https://ollama.com/library
- **Stable Diffusion WebUI**: https://github.com/AUTOMATIC1111/stable-diffusion-webui
- **Python Requests Documentation**: https://requests.readthedocs.io
- **Pillow (PIL) Documentation**: https://pillow.readthedocs.io

## üìÑ License

This project is licensed under the MIT License. See the LICENSE file for details.

## ü§ù Contributing

Contributions are welcome! Please feel free to:
- Report bugs
- Suggest improvements
- Submit pull requests

## ‚ùì FAQ

**Q: Can I use this with CPU only?**
A: Yes, but it will be significantly slower. Expect 5-10 minutes per image on CPU vs 30 seconds on GPU.

**Q: Can I run multiple instances simultaneously?**
A: Not recommended unless you have multiple GPUs. Use different ports instead.

**Q: What about other Ollama models?**
A: Any model can be used for prompt generation, but `brxce/stable-diffusion-prompt-generator` is optimized for this task.

**Q: How do I add new SD checkpoints?**
A: Simply add the exact filename to the `AVAILABLE_MODELS` list and update `MODEL_SELECTION_INDEX`. **Important**: Use only the filename without the hash (e.g., `model.safetensors`, not `model.safetensors [abc123]`).

**Q: I see a model with `[hash]` in the UI. How do I add it?**
A: Copy only the filename without the bracketed hash. For example:
- UI shows: `realisticVisionV60B1 [a0d5b3e123]`
- Use in code: `"realisticVisionV60B1.safetensors"`

**Q: Why am I getting a "Model not found" error?**
A: Check that:
1. The filename matches exactly (case-sensitive on Linux/Mac)
2. You're not including the hash suffix `[abc123]`
3. The model file exists in `models/Stable-diffusion/` folder in your SD WebUI directory

**Q: Can I generate multiple images in a batch?**
A: Yes! Modify `batch_size` in the `sd_payload`. Note: Higher batch sizes require more VRAM.

---

**Last Updated**: November 2025  
**Maintainer**: Sachin Paunikar