{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb9b1b-c7d1-418d-9429-dacd146deae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==2.1.2 in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (4.15.0)\n",
      "Requirement already satisfied: sympy in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from torch==2.1.2) (2025.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from jinja2->torch==2.1.2) (3.0.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\envs\\face_recognition_env\\lib\\site-packages (from sympy->torch==2.1.2) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies (run once if needed)\n",
    "# ! pip install requests pillow\n",
    "# ! pip install torch torchvision xformers  # Only if running SD WebUI locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca2c895-ecc5-40ff-bb31-369c39577587",
   "metadata": {},
   "source": [
    "## Step 1: Environment Check & Dependencies\n",
    "\n",
    "Verify that all required packages and CUDA support are available.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aed8a02-ba5c-4983-8268-6a7d72631f3a",
   "metadata": {},
   "source": [
    "## Step 4: Generate and Save Image\n",
    "\n",
    "Create an image using the enhanced prompts via the Stable Diffusion txt2img API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079818e8-a607-45e6-af56-2484891fb1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
      "    PyTorch 2.1.0+cu121 with CUDA 1201 (you have 2.1.0+cu118)\n",
      "    Python  3.10.11 (you have 3.10.19)\n",
      "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
      "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
      "  Set XFORMERS_MORE_DETAILS=1 for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "0.16.0+cu118\n",
      "True\n",
      "0.0.22.post7\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import xformers\n",
    "\n",
    "print(\"üîç Environment Check:\")\n",
    "print(f\"  PyTorch Version: {torch.__version__}\")\n",
    "print(f\"  TorchVision Version: {torchvision.__version__}\")\n",
    "print(f\"  CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  CUDA Device: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"  xFormers Version: {xformers.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9655143c-be18-4946-9846-7ddb634f5c43",
   "metadata": {},
   "source": [
    "## Step 2: Configuration & Utility Functions\n",
    "\n",
    "Define API endpoints, available models, and helper functions for model switching and prompt parsing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefb06c-5a4e-4966-b950-1cddeae6fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import base64\n",
    "import json # Included for future-proofing advanced JSON parsing\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from IPython.display import display # Specifically for displaying images in Jupyter/Colab\n",
    "import time\n",
    "import os\n",
    "\n",
    "# ============================================================================\n",
    "# üîß CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "SD_API_URL = \"http://127.0.0.1:7860\"              # Stable Diffusion WebUI\n",
    "OLLAMA_URL = \"http://localhost:11434/api/generate\"  # Ollama API\n",
    "\n",
    "# API Timeouts\n",
    "TIMEOUT_OLLAMA = 120 # Seconds for prompt generation\n",
    "TIMEOUT_SD_API = 300 # Seconds for image generation (adjust based on your GPU speed)\n",
    "\n",
    "# üé® Available Stable Diffusion Checkpoints (Add the full filename as needed)\n",
    "\n",
    "# --- Model Auto-Discovery Implementation ---\n",
    "MODEL_FOLDER_PATH = r\"C:\\AI\\stable-diffusion-webui-master\\models\\Stable-diffusion\"\n",
    "SUPPORTED_EXTENSIONS = ('.safetensors', '.ckpt')\n",
    "\n",
    "def auto_discover_models(folder_path: str) -> list[str]:\n",
    "    \"\"\"Lists model files in the specified directory.\"\"\"\n",
    "    if not os.path.isdir(folder_path):\n",
    "        print(f\"‚ùå Error: Model directory not found at: {folder_path}\")\n",
    "        return []\n",
    "    \n",
    "    # Filter files ending with supported extensions\n",
    "    models = [f for f in os.listdir(folder_path) if f.endswith(SUPPORTED_EXTENSIONS)]\n",
    "    \n",
    "    # Simple sort to make selection predictable (alphabetical)\n",
    "    models.sort()\n",
    "    return models\n",
    "\n",
    "AVAILABLE_MODELS = auto_discover_models(MODEL_FOLDER_PATH)\n",
    "\n",
    "# Check if any models were found\n",
    "if not AVAILABLE_MODELS:\n",
    "    print(\"‚ö†Ô∏è Warning: No models found via auto-discovery. Using a fallback list.\")\n",
    "    AVAILABLE_MODELS = [\n",
    "        \"v1-5-pruned-emaonly.safetensors\", # Fallback default\n",
    "    ]\n",
    "    MODEL_SELECTION_INDEX = 0\n",
    "elif len(AVAILABLE_MODELS) > 1:\n",
    "    MODEL_SELECTION_INDEX = 1 # Select the second model in the list (if available)\n",
    "else:\n",
    "    MODEL_SELECTION_INDEX = 0\n",
    "    \n",
    "MODEL_TO_USE = AVAILABLE_MODELS[MODEL_SELECTION_INDEX]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Default negative keywords (used as a base for Ollama or as a fallback)\n",
    "NEGATIVE_PROMPT_KEYWORDS = \"low quality, blurry, worst quality, extra limbs, deformed, bad anatomy, jpeg artifacts\"\n",
    "\n",
    "print(f\"‚úÖ Configuration Loaded\")\n",
    "print(f\"  Total Models Found: {len(AVAILABLE_MODELS)}\")\n",
    "print(f\"  Selected Model Index ({MODEL_SELECTION_INDEX}): {MODEL_TO_USE}\")\n",
    "print(f\"  SD API: {SD_API_URL}\")\n",
    "print(f\"  Ollama API: {OLLAMA_URL}\")\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# üõ†Ô∏è UTILITY FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def switch_sd_checkpoint(model_name: str, api_url: str = SD_API_URL) -> bool:\n",
    "    \"\"\"\n",
    "    Switches the active Stable Diffusion model checkpoint via the A1111 API.\n",
    "    \n",
    "    This function calls the /sdapi/v1/options endpoint to change the currently\n",
    "    loaded model checkpoint. The model must exist in the WebUI's models directory.\n",
    "    \n",
    "    Args:\n",
    "        model_name (str): Exact filename of the model checkpoint to load\n",
    "        api_url (str): Base URL of the Stable Diffusion WebUI API\n",
    "    \n",
    "    Returns:\n",
    "        bool: True if the switch was successful, False otherwise\n",
    "    \n",
    "    Example:\n",
    "        >>> switch_sd_checkpoint(\"realisticVisionV60B1_v51HyperVAE.safetensors\")\n",
    "        ‚úÖ Model switch successful.\n",
    "        True\n",
    "    \"\"\"\n",
    "    options_endpoint = f\"{api_url}/sdapi/v1/options\"\n",
    "    switch_payload = {\"sd_model_checkpoint\": model_name}\n",
    "    \n",
    "    print(f\"üîÑ Switching model to: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(options_endpoint, json=switch_payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"‚úÖ Model switch successful.\")\n",
    "            time.sleep(2)  # Brief pause to ensure model is loaded\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå API Call Failed. Status Code: {response.status_code}\")\n",
    "            try:\n",
    "                print(\"   API Error Details:\", response.json())\n",
    "            except requests.exceptions.JSONDecodeError:\n",
    "                print(\"   Raw Response:\", response.text)\n",
    "            return False\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"‚ùå Connection/Request Error: {e}\")\n",
    "        print(\"   Please ensure the Stable Diffusion Web UI is running with the --api flag.\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def parse_prompt_output(prompt_string: str) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Intelligently parses LLM output into positive and negative prompt components.\n",
    "    \n",
    "    This function attempts to split the LLM's response using common delimiters\n",
    "    that separate positive and negative prompts. It supports multiple delimiter\n",
    "    formats to handle variations in LLM output formatting.\n",
    "    \n",
    "    Supported delimiters (case-sensitive):\n",
    "    - \"NEGATIVE PROMPT:\"\n",
    "    - \"Negative Prompt:\"\n",
    "    - \"NEGATIVE:\"\n",
    "    - \"Negative:\"\n",
    "    \n",
    "    Args:\n",
    "        prompt_string (str): Raw output from the Ollama LLM\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[str, str]: A tuple of (positive_prompt, negative_prompt)\n",
    "                        If no delimiter is found, returns (full_string, \"\")\n",
    "    \n",
    "    Example:\n",
    "        >>> output = \"Beautiful sunset. Negative Prompt: ugly, blurry\"\n",
    "        >>> parse_prompt_output(output)\n",
    "        ('Beautiful sunset.', 'ugly, blurry')\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define common delimiters the prompt generator model might use\n",
    "    delimiters = [\"NEGATIVE PROMPT:\", \"Negative Prompt:\", \"NEGATIVE:\", \"Negative:\"]\n",
    "    \n",
    "    for delimiter in delimiters:\n",
    "        if delimiter in prompt_string:\n",
    "            parts = prompt_string.split(delimiter, 1)\n",
    "            positive = parts[0].strip().strip(',').strip()\n",
    "            negative = parts[1].strip().strip(',').strip()\n",
    "            return positive, negative\n",
    "\n",
    "    # Fallback: If no delimiter found, assume the whole string is the positive prompt\n",
    "    print(\"‚ö†Ô∏è Warning: Could not find negative prompt delimiter in LLM output.\")\n",
    "    print(\"   Using full string as positive prompt with empty negative prompt.\")\n",
    "    return prompt_string, \"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878a0e8a-6cf0-46ae-b42f-6e4d98d2a780",
   "metadata": {},
   "source": [
    "## Step 3: Generate Enhanced Prompt with Ollama\n",
    "\n",
    "Use the local Ollama LLM to transform a basic idea into a detailed, high-quality prompt.\n",
    "The model will generate a prompt with both positive (main description) and negative (what to avoid) components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f110d-7ff4-4213-afdf-93ca9dcdba9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# ü§ñ STEP 1: OLLAMA PROMPT GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ü§ñ STEP 1: Generating Enhanced Prompt with Ollama\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "NEGATIVE_PROMPT_KEYWORDS = \"low quality, blurry, worst quality, extra limbs, deformed, bad anatomy, jpeg artifacts\"\n",
    "\n",
    "# Define a base prompt idea (customize this!)\n",
    "base_prompt = (\n",
    "    \"A portrait of a young woman, golden hour sunlight, soft focus, vivid colors, intricate details. \"\n",
    "    \"Generate a Stable Diffusion prompt that includes a detailed positive prompt and a section for a \"\n",
    "    f\"negative prompt with these keywords: {NEGATIVE_PROMPT_KEYWORDS}. \"\n",
    "    \"Ensure the negative section is clearly labeled 'Negative Prompt:'\"\n",
    ")\n",
    "\n",
    "ollama_data = {\n",
    "    \"model\": \"brxce/stable-diffusion-prompt-generator\",\n",
    "    \"prompt\": base_prompt,\n",
    "    \"format\": \"json\",\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "enhanced_prompt = None\n",
    "positive_prompt = \"\"\n",
    "negative_prompt = NEGATIVE_PROMPT_KEYWORDS  # Default fallback\n",
    "\n",
    "print(f\"üìù Base Prompt: {base_prompt[:80]}...\")\n",
    "print(f\"üîÑ Calling Ollama API: {OLLAMA_URL}\")\n",
    "\n",
    "try:\n",
    "    ollama_response = requests.post(OLLAMA_URL, json=ollama_data, timeout=TIMEOUT_OLLAMA)\n",
    "    \n",
    "    if ollama_response.status_code == 200:\n",
    "        prompt_json = ollama_response.json()\n",
    "        if 'response' in prompt_json:\n",
    "            enhanced_prompt = prompt_json.get(\"response\")\n",
    "            positive_prompt, negative_prompt = parse_prompt_output(enhanced_prompt)\n",
    "            print(\"‚úÖ Ollama Prompt Generation Success!\")\n",
    "            print(f\"\\nüìå Generated Positive Prompt:\")\n",
    "            print(f\"   {positive_prompt[:100]}...\")\n",
    "            print(f\"\\n‚õî Generated Negative Prompt:\")\n",
    "            print(f\"   {negative_prompt}\")\n",
    "        else:\n",
    "            print(\"‚ùå Ollama response missing 'response' key.\")\n",
    "            print(f\"   Response keys: {prompt_json.keys()}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Ollama API call failed (Status: {ollama_response.status_code})\")\n",
    "        print(f\"   Response: {ollama_response.text}\")\n",
    "\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå FATAL ERROR: Could not connect to Ollama.\")\n",
    "    print(f\"   Make sure Ollama is running: ollama serve\")\n",
    "    print(f\"   And the model is pulled: ollama pull brxce/stable-diffusion-prompt-generator\")\n",
    "\n",
    "except requests.exceptions.Timeout:\n",
    "    print(\"‚ùå Timeout: Ollama took too long to respond.\")\n",
    "    print(\"   Try increasing the timeout value or check system resources.\")\n",
    "\n",
    "# Fallback in case Ollama fails\n",
    "if not positive_prompt:\n",
    "    positive_prompt = \"A masterwork portrait of a young woman, volumetric golden hour light, highly detailed face, cinematic focus, professional photography\"\n",
    "    negative_prompt = NEGATIVE_PROMPT_KEYWORDS\n",
    "    print(\"\\n‚ö†Ô∏è Using FALLBACK Prompts (Ollama failed or not responding).\")\n",
    "    print(f\"   Positive: {positive_prompt}\")\n",
    "    print(f\"   Negative: {negative_prompt}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2495f50e-b8d1-48c1-a6c8-f50aaa68e02d",
   "metadata": {},
   "source": [
    "## Step 2: Switch Active Model\n",
    "\n",
    "Select and load the desired Stable Diffusion checkpoint from the AVAILABLE_MODELS list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d537585-ae09-4da5-b1b9-70d5b9059a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## üîÑ Step 3: Switching Stable Diffusion Model\n",
      "Attempting to switch model to: **protogenX34Pruned.8NEd.safetensors [ef8629e2c8]**\n",
      "‚úÖ Model switch successful.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# üîÑ STEP 2: STABLE DIFFUSION MODEL SWITCHING\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîÑ STEP 2: Switching Stable Diffusion Model\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "success = switch_sd_checkpoint(MODEL_TO_USE)\n",
    "\n",
    "if not success:\n",
    "    print(\"\\n‚ö†Ô∏è Warning: Model switch failed. Proceeding anyway...\")\n",
    "    print(\"   The WebUI may still have loaded the model or it might not exist.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8744b849-6afe-400a-9907-54d12f744bda",
   "metadata": {},
   "source": [
    "## Step 3: Generate Image via Stable Diffusion\n",
    "\n",
    "Use the enhanced prompts to generate an image. The image will be saved and displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de86ba8e-0674-49ca-a4bb-17f41cdb4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# üñºÔ∏è STEP 3: STABLE DIFFUSION IMAGE GENERATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üñºÔ∏è STEP 3: Generating Image via txt2img API\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Configure generation parameters\n",
    "sd_payload = {\n",
    "    \"prompt\": positive_prompt,\n",
    "    \"negative_prompt\": negative_prompt,\n",
    "    \"steps\": 25,                      # Quality vs speed trade-off\n",
    "    \"cfg_scale\": 7,                   # Prompt adherence (5-15 typical)\n",
    "    \"sampler_index\": \"Euler a\",       # Sampling algorithm\n",
    "    \"width\": 768,                     # Must be multiple of 64\n",
    "    \"height\": 512,                    # Must be multiple of 64\n",
    "    \"batch_size\": 1                   # Number of images to generate\n",
    "}\n",
    "\n",
    "print(f\"üìã Generation Parameters:\")\n",
    "print(f\"   Steps: {sd_payload['steps']}\")\n",
    "print(f\"   CFG Scale: {sd_payload['cfg_scale']}\")\n",
    "print(f\"   Resolution: {sd_payload['width']}x{sd_payload['height']}\")\n",
    "print(f\"   Sampler: {sd_payload['sampler_index']}\")\n",
    "print(f\"\\n‚è≥ Generating image... (this may take 30-60 seconds)\")\n",
    "\n",
    "try:\n",
    "    # Call the txt2img API with extended timeout for generation\n",
    "    start_time = time.time()\n",
    "    sd_response = requests.post(\n",
    "        f\"{SD_API_URL}/sdapi/v1/txt2img\", \n",
    "        json=sd_payload, \n",
    "        timeout=TIMEOUT_SD_API  # 5 minute timeout for generation\n",
    "    )\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    sd_response.raise_for_status()  # Raise HTTPError for bad responses\n",
    "    \n",
    "    sd_result = sd_response.json()\n",
    "\n",
    "    if 'images' in sd_result and sd_result['images']:\n",
    "        print(f\"‚úÖ Image generation successful in {elapsed_time:.1f} seconds!\")\n",
    "        print(f\"   Generated {len(sd_result['images'])} image(s)\")\n",
    "        \n",
    "        # Process and save the first image\n",
    "        img_b64 = sd_result['images'][0]\n",
    "        img_bytes = base64.b64decode(img_b64)\n",
    "        img = Image.open(BytesIO(img_bytes))\n",
    "        \n",
    "        # Generate filename from model name\n",
    "        model_short_name = MODEL_TO_USE.split('.')[0][:20]\n",
    "        filename = f\"sd_generated_output_{model_short_name}_{int(time.time())}.png\"\n",
    "        img.save(filename)\n",
    "        print(f\"\\nüñºÔ∏è Image saved as: {filename}\")\n",
    "        print(f\"   Dimensions: {img.size[0]}x{img.size[1]}\")\n",
    "        \n",
    "        # Display image in Jupyter if available\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(img)\n",
    "        except ImportError:\n",
    "            print(\"   (Image not displayed - not running in Jupyter)\")\n",
    "\n",
    "    else:\n",
    "        print(\"‚ùå Image generation failed.\")\n",
    "        print(f\"   'images' key not found or list is empty.\")\n",
    "        print(f\"   Response keys: {sd_result.keys()}\")\n",
    "        if 'info' in sd_result:\n",
    "            print(f\"   Info: {sd_result['info']}\")\n",
    "\n",
    "except requests.exceptions.HTTPError as errh:\n",
    "    print(f\"‚ùå HTTP Error (SD API): {errh}\")\n",
    "    print(f\"   Status Code: {sd_response.status_code}\")\n",
    "    print(f\"   Response: {sd_response.text}\")\n",
    "    \n",
    "except requests.exceptions.Timeout:\n",
    "    print(f\"‚ùå Timeout Error: Image generation took too long (>300s)\")\n",
    "    print(f\"   Try reducing resolution, steps, or batch_size\")\n",
    "    \n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(f\"‚ùå Connection Error: Could not reach Stable Diffusion WebUI\")\n",
    "    print(f\"   Make sure SD WebUI is running with: python launch.py --api --no-half\")\n",
    "    \n",
    "except requests.exceptions.RequestException as err:\n",
    "    print(f\"‚ùå Request Error (SD API): {err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12b93c-2a1d-4ce3-bf63-c93ec1148052",
   "metadata": {},
   "outputs": [],
   "source": [
    "## üìù Notes & Next Steps\n",
    "\n",
    "### Tips for Better Results:\n",
    "- **Adjust `cfg_scale`** (7-10): Higher values enforce the prompt more strictly\n",
    "- **Increase `steps`** (30-50): More steps = better quality but slower generation\n",
    "- **Modify `sampler_index`**: Try \"DPM++ 2M\", \"DDIM\", or others\n",
    "- **Change resolution**: Use 512√ó512 for faster generation, 768√ó768+ for more detail\n",
    "- **Customize prompts**: Edit the `base_prompt` and `NEGATIVE_PROMPT_KEYWORDS`\n",
    "\n",
    "### Troubleshooting:\n",
    "- If you get a connection error, ensure both services are running:\n",
    "  - Ollama: `ollama serve`\n",
    "  - SD WebUI: `python launch.py --api --no-half`\n",
    "- If image generation is slow, reduce `steps` or `resolution`\n",
    "- If you get CUDA errors, add `--lowvram` flag to the SD WebUI launch command\n",
    "\n",
    "### Generate Multiple Images:\n",
    "Run the image generation cell multiple times with different prompts or parameters.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
